{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd_path = os.path.dirname(os.path.abspath(__file__))\n",
    "data = pd.read_csv(os.path.join(\n",
    "    pwd_path, 'TextClassification Dataset - main (3).csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpeza de dados e remoção de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    stop_words = set(stopwords.words('portuguese'))\n",
    "    cleaned_url = ' '.join(word for word in re.split(\n",
    "        '[^a-zA-Z6]', url) if word not in stop_words).lower()\n",
    "    cleaned_url = re.sub('www', '', cleaned_url)\n",
    "\n",
    "    return cleaned_url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento do modelo utilizando CountVectorizer e Redes Neurais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"I'll start the training now...\")\n",
    "t1 = time.time()\n",
    "data['cleaned_username'] = data['username'].apply(clean_url)\n",
    "\n",
    "train_data, test_data = train_test_split(data,\n",
    "                                         test_size=0.2,\n",
    "                                         random_state=42)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "x_train = vectorizer.fit_transform(train_data['cleaned_username'])\n",
    "x_test = vectorizer.transform(test_data['cleaned_username'])\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(350,), activation='relu',\n",
    "                    solver='adam',\n",
    "                    max_iter=4500, random_state=42, verbose=True)\n",
    "model = clf.fit(x_train, train_data['clientes'])\n",
    "\n",
    "t = time.time()\n",
    "elapsed_time = t - t1\n",
    "minutes = int(elapsed_time // 60)\n",
    "seconds = int(elapsed_time % 60)\n",
    "print(f'Training completed in: {minutes}m {seconds}s \\n')\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(test_data['clientes'], y_pred)\n",
    "accuracy = round(float(accuracy * 100), 4)\n",
    "\n",
    "FILENAME = 'text_model2.pkl'\n",
    "VECTORIZER_FILE = 'text_vectorizer2.pkl'\n",
    "joblib.dump(model, FILENAME)\n",
    "joblib.dump(vectorizer, VECTORIZER_FILE)\n",
    "\n",
    "print(f'Accuracy of the Neural Network: {accuracy}%')\n",
    "print(' ')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
